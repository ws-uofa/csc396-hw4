{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14a21f6c-022c-4c66-84a9-1eedfbdb3b95",
   "metadata": {},
   "source": [
    "### Imports and Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452c7aeb-0f3f-473d-a2cf-3d60fcaa7534",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "# Check for GPU availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load Model and Tokenizer\n",
    "model_name = \"microsoft/deberta-v3-base\"\n",
    "print(f\"Loading {model_name}...\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name).to(device)\n",
    "\n",
    "model.eval() # Set model to evaluation mode (disables dropout, etc.)\n",
    "print(\"Model loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7981e7d-d2e9-47ba-b77a-b628dda3b012",
   "metadata": {},
   "source": [
    "### Tasks 1 & 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75ac470-0898-41a4-a8b5-934846751b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data structures to store running sums and counts for averaging\n",
    "token_embedding_sums = defaultdict(lambda: torch.zeros(model.config.hidden_size).to(device))\n",
    "token_counts = defaultdict(int)\n",
    "token_id_to_word = {} # To map IDs back to text for readability later\n",
    "\n",
    "filename = \"assignment4-dataset.txt\"\n",
    "\n",
    "print(\"Processing file...\")\n",
    "\n",
    "with open(filename, 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "    # We use torch.no_grad() because we don't need gradients for inference\n",
    "    # This saves significant memory and computation\n",
    "    with torch.no_grad():\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if not line: continue  # Skip empty lines\n",
    "\n",
    "            # --- Task 1: Tokenize individual sentence ---\n",
    "            # return_tensors=\"pt\" gives us PyTorch tensors\n",
    "            inputs = tokenizer(line, return_tensors=\"pt\").to(device)\n",
    "            \n",
    "            input_ids = inputs[\"input_ids\"][0] # Flatten batch dimension\n",
    "            \n",
    "            # --- Task 2a: Generate Contextualized Embeddings ---\n",
    "            outputs = model(**inputs)\n",
    "            \n",
    "            # last_hidden_state shape: (batch_size, seq_len, hidden_size)\n",
    "            # We squeeze the batch dimension (index 0)\n",
    "            embeddings = outputs.last_hidden_state[0] \n",
    "            \n",
    "            # --- Accumulate Data for Averaging ---\n",
    "            for i, token_id in enumerate(input_ids):\n",
    "                token_id = token_id.item()\n",
    "                embedding_vector = embeddings[i]\n",
    "                \n",
    "                # Store the mapping so we know what the token looks like textually\n",
    "                if token_id not in token_id_to_word:\n",
    "                    token_id_to_word[token_id] = tokenizer.decode([token_id])\n",
    "                \n",
    "                # Add current embedding to the sum for this specific token ID\n",
    "                token_embedding_sums[token_id] += embedding_vector\n",
    "                token_counts[token_id] += 1\n",
    "\n",
    "print(f\"Processing complete. Found {len(token_embedding_sums)} unique tokens.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1233443-9a0b-4b7c-b1ae-b56974045fb2",
   "metadata": {},
   "source": [
    "### Compute Averages and Display Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2596ed63-ad33-4743-8929-4befe3da0061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store the final averaged embeddings\n",
    "# Format: { token_id: torch_tensor_of_average_embedding }\n",
    "average_token_embeddings = {}\n",
    "\n",
    "for token_id, embedding_sum in token_embedding_sums.items():\n",
    "    count = token_counts[token_id]\n",
    "    # Calculate mean: sum / count\n",
    "    average_token_embeddings[token_id] = embedding_sum / count\n",
    "\n",
    "# --- Verification / Display ---\n",
    "print(f\"{'Token ID':<10} | {'Token Text':<15} | {'Count':<5} | {'Embedding Shape'}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Print first 10 tokens as an example\n",
    "for i, (token_id, avg_emb) in enumerate(average_token_embeddings.items()):\n",
    "    if i >= 10: break\n",
    "    \n",
    "    token_text = token_id_to_word[token_id]\n",
    "    count = token_counts[token_id]\n",
    "    \n",
    "    # Move to CPU for printing shape/values if needed\n",
    "    avg_emb_cpu = avg_emb.cpu()\n",
    "    \n",
    "    print(f\"{token_id:<10} | {token_text:<15} | {count:<5} | {list(avg_emb_cpu.shape)}\")\n",
    "\n",
    "# Example: Accessing the vector for a specific token\n",
    "# print(average_token_embeddings[list(average_token_embeddings.keys())[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454862f2-0e34-465a-9bfa-6b7d9cc08f94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "",
   "name": ""
  },
  "language_info": {
   "name": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
